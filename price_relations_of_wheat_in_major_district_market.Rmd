---
title: Price relations wheat in major domestic and international markets
author: "Samita Paudel"
date: "6/28/2019"
output: 
  bookdown::pdf_document2:
    latex_engine: xelatex
    keep_tex: true
    toc: false
    includes:
      in_header: template_header.tex
  word_document:
    # reference_docx: draft_word_template.docx
fontsize: 12pt
geometry: margin=1in
citecolor: DodgerBlue4
linestretch: 1
bibliography: bibliographies.bib
link-citations: yes
---

```{r setup, include=FALSE}
require(AER)
require(tidyverse)
require(forecast)
require(tsibble)
require(ggfortify)
require(fable)
require(fabletools)
require(tseries)
require(sf)
require(units)
# require(timetk)
# require(timeSeries)
# require(timeDate)
require(urca)
# require(rvest)
# require(rebus)
require(lubridate)
# install.packages("imputeTS") # useful for imputation

theme_set(theme_bw())

knitr::opts_chunk$set(tidy = FALSE, echo = FALSE, cache = TRUE, message = F, warning = F)
options(htmltools.dir.version = FALSE, 
        # knitr.table.format = "latex",
        kableExtra.latex.load_packages = FALSE)
```


```{r handy-functions}
# named group split (copied from: https://github.com/tidyverse/dplyr/issues/4223)
named_group_split <- function(.tbl, ...) {
  grouped <- group_by(.tbl, ...)
  names <- rlang::eval_bare(rlang::expr(paste(!!!group_keys(grouped), sep = " / ")))

  grouped %>% 
    group_split() %>% 
    rlang::set_names(names)
}

```

# Notes

- Formulate simple linear regression
- Multicollinearlity check...refer to Variance Inflation Factor
- Plot time series
- Autocorrelation check
- Drop variables with high multicollinarity
- Use 
  - Darbin-Watson test for autocorrelation test (D-statistic), or
  - Brueuch Godfrey test for autocorrelation
- Use
  - Bursch-pagan test for heteroscadesticity
  - Or plot histogram
- In time series analysis, 
  - Use regression with OLS
  - Plot data of each series (Fuel, prices, temperature)
  - Test dickey fueller test (Use no trend, no drift), use all possibility
  - Use augmented dickey fueller test if dickey fueller test does not capture the essense
  - Perform detrending with first order difference

# Why domestic price is studied at district level

- Until recently, before federal structure of governance was into force, planning, budgeting, service delivery and policy interventions in Agriculture were all excised through district level bodies. Each district was itself accountable for market information accrual and reporting. Hence, most reliable form of price series data would be district level itself.
- Districts present isolated markets and well organized customer segments surrounding that. For e.g., food grain retail market of kathmandu is drastically different from that of kailali, because while in the former consumer segment has a larger role to play in determining of market demand, the market of farwestern terai region has significant share of producer segments in determining what and when to produce.
- District present different socio-economic narrative for food commodity trade which is heavily affected by the geographical context of the district itself. For e.g., Rupandehi market is more closely tied to bordering Indian market, because of minimal to none customs intervention in cross-country trade of food grain. The price effects of indian districts are more easily reflected in border region market prices, than in distant market such as Jumla and Surkhet. 
- District markets information systems are more organized than local level markets, mostly because there are factors that buffer price volatility in district level. For e.g., government intervene through subsidized input supply, facilitated by district level agriculture offices when prices of agricultural inputs are hightened. Also service delivery system, for example that providing subsidized farmers loan, is carried out at district level.

# Why only few domestic markets were selected for study

- These markets either have a large production volumes or strong consumer segment. Because districts of terai, and mostly those of Central to Farwestern region, show consistently high annual production volume (Terai is also dubbed grain basket of Nepal) major producer districts in terai -- Kailali, Rupandehi, Parsa are included in the study. At the same time Chitwan and Kathmandu districts have prominance of consumers.
- Some of the features that justify suitability of inclusion of abovementioned districts are presented:
  - Kailali district lies in farwestern region. It borders with India through Uttar Pradesh state. The district has huge chunks of land annually allocated to Wheat production (How much in total ???, what percentage of total wheat cultivated area ???). The farmer segment comprises mainly of Tharu community.
  - Rupandehi district is located in Western terai region. The district adjoining with Indian market of Uttar Pradesh state, likewise, has large volume of grain production arising from Wheat cultivation.
  - Parsa district lies in Central terai part of Nepal. It border with India through Bihar state and the district cultivates Wheat in large volume (areawise how much ???).
- Kathmandu and Chitwan markets are mostly dominanted by consumer segment, hence the retail price series of these districts are expected to differ from that of producer market districts.
- ???Some of the food market features of Kathmandu and Surkhet districts???
- Treatment of isolated markets into arbitrary category of consumer and producer districts will provide a more complete picture of the situation of region they represent -- Farwestern terai, Western-central terai and Eastern-central terai regions, respectively. This form of classification is expected to improve interpretability and overall increase predictive accuray of model in the face of price shocks.

<!-- ```{r} -->
<!-- knitr::include_graphics("https://github.com/DeependraD/plotting_geographical_features/raw/master/outputs/npl_top_wheat_growing_districts_productionwise.png") -->
<!-- ``` -->


# Dependent variables

## Retail price of wheat in major domestic markets

Price series of domestic markets were selected for study. The data represent imbalanced series of following 5 districts:

Kailali, Rupandehi, Parsa, Kathmandu, Chitwan

```{r nepal-wheat-retail}

# import data
retail_pr_np_wfp <- read_csv("./data/prices_nepal/wfp_food_prices_nepal_markethubwise_nepal_2005-2019.csv", skip = 1) %>% 
  # convenient date type to work with
  mutate(date = yearmonth(date)) %>% 
  # deselect unnecessary columns
  select(-last_col(), -country, -currency, -adm1id, -catid, -cmid, -mktid, -ptid, -umid, -sn, -unit) %>% 
  # include only food items (filter out fuel)
  filter(cmname == 'Wheat - Retail') %>%
  as_tsibble(index = date, key = c(cmname, mktname)) %>% 
  # just to remove bloating columns, perfrom group_by and summarize
  group_by(admname, mktname) %>%
  summarise(price = mean(price, na.rm = T)) %>%
  ungroup() %>% 
  mutate(cmname = "Wheat")

# subset the data for some districtwise market series only
retail_mhub <- retail_pr_np_wfp %>% 
  filter(mktname %in% c("Kailali", "Rupandehi", "Parsa", "Kathmandu", "Chitwan"))
```


```{r weather-nepal-districts}
# weather data

## obtain precipitation data from NASA
# parameters list is available form
# nasapower::parameters

# # `par = PRECTOT` (Precipitation total)
# # define coordinates of various districts
# latlong_chitwan = c(27.452831, 83.940157, 27.870032, 84.663882)
# latlong_kathmandu = c(27.673692, 85.277209, 27.749526, 85.367674)
# latlong_parsa = c(27.016707, 84.470661, 27.421539, 85.001438)
# latlong_kailali = c(28.426580, 80.49756, 28.96625, 81.25836)
# latlong_rupandehi = c(27.353300, 83.167320, 27.669970, 83.641100)

# import data
weather_address <- list.files("./data/weather_nepal", full.names = T)

weather_markets_df <- map_dfr(weather_address, ~read_csv(.x, na = "-99", skip = 11), .id = "mktname") %>% 
  mutate(mktname = fct_recode(mktname, "Parsa" = "1", "Kathmandu" = "2", 
                              "Rupandehi" = "3", "Chitwan" = "4", 
                              "Kailali" = "5")) %>%
  mutate(date = yearmonth(strptime(paste(YEAR, DOY, sep = "-"), format = "%Y-%j", tz = "Asia/Kathmandu"))) %>% 
  select(-YEAR, -DOY) %>% 
  group_by(date, mktname) %>% 
  summarise(PRECTOT = mean(PRECTOT, na.rm = TRUE)) %>% 
  mutate(country = "Nepal", 
         currency = "NPR", 
         cmname = "Wheat")
```


```{r foreign-exchange-data}
# foreign exchange data
# forex_json <- rjson::fromJSON(file = "~/../Desktop/exportForexJSON.php.json", simplify = F)
# forex_df <- forex_json[[1]][[1]] %>% bind_rows()
# write_csv(forex_df, "./data/forex_data_npl.csv", "")

forex_df <- readxl::read_xlsx("./data/forex_data_npl.xlsx", sheet = "forex_data_npl")
forex_ts <- forex_df %>% 
  mutate(Date = as_date(Date)) %>% 
  distinct(Date, BaseCurrency, TargetCurrency, .keep_all = T) %>% 
  as_tsibble(index = Date, key = c(BaseCurrency, TargetCurrency)) %>% 
  fill_gaps()

forex_ts <- forex_ts %>% 
    mutate(TargetBuy = na_if(TargetBuy, 0), 
         TargetSell = na_if(TargetSell, 0)) %>% 
  mutate(TargetBuy = if_else(is.nan(TargetBuy), NA_real_, TargetBuy), 
         TargetSell = if_else(is.nan(TargetSell), NA_real_, TargetSell)) %>% 
  group_by(BaseCurrency, TargetCurrency) %>% 
  index_by(date_yrmon = yearmonth(Date)) %>% 
  summarise_at(c("BaseValue", "TargetBuy", "TargetSell"), list(~mean(., na.rm = T))) %>% 
  ungroup()


forex_ts %>%
  filter(!is.nan(TargetBuy) & !is.nan(TargetSell)) %>%
  filter(BaseCurrency %in% c("EUR", "USD")) %>% 
  ggplot() +
  geom_line(aes(x = date_yrmon, y = TargetBuy, color = BaseCurrency))

# require(rvest)
# forex_currency_codes <- ("https://en.wikipedia.org/wiki/ISO_4217")
# forex_currency_codes_df <- read_html(forex_currency_codes) %>% 
#   html_nodes(xpath = '//*[@id="mw-content-text"]/div/table[2]') %>% 
#   .[[1]] %>%
#   html_table() %>% 
#   as_tibble() %>% 
#   select(Code, Currency)
# forex_currency_codes_df %>% write_csv("./data/forex_currency_codes.csv", "")
# forex_currency_codes_df <- read_csv("./data/forex_currency_codes.csv")

# forex season plot
# forex_ts %>% 
#   left_join(forex_currency_codes_df, by = c("BaseCurrency"="Code")) %>% 
#   filter(!is.nan(TargetBuy) & !is.nan(TargetSell)) %>%
#   filter(!BaseCurrency %in% c("INR", "JPY")) %>% # INR and JPY are consistent
#   # distinct(Currency, BaseCurrency)
#   filter(BaseCurrency %in% c("EUR", "USD")) %>% 
#   feasts::gg_season(y = TargetBuy)

```


```{r fuel-annual-nepal}
# annual/biannual series of fuel prices
fuel_biannual_series <- readxl::read_xls("./data/worldbank_diesel_retail.xls", sheet = "Data", skip = 3) %>% 
  filter(`Country Name` %in% c("Nepal", "India", "Canada")) %>% 
  select(-`Indicator Name`, -`Indicator Code`, country = `Country Name`, country_code = `Country Code`) %>% 
  pivot_longer(cols = `1960`:`2019`, names_to = "date", values_to = "price_usd") %>% 
  filter(!is.na(price_usd)) %>% 
  mutate(date = yearmonth(date)) %>% 
  as_tsibble(index = date, key = c(country)) %>% 
  left_join(forex_ts %>%
  filter(BaseCurrency == "USD") %>% 
  rename(date = date_yrmon) %>% 
  select(-TargetCurrency, -BaseCurrency, -BaseValue)) %>% 
  mutate(price = price_usd * (TargetBuy+TargetSell)/2) %>% 
  select(-TargetBuy, -TargetSell, -price_usd) %>% 
  filter(country == "Nepal")


fuel_npl_1719 <- readxl::read_xlsx("./data/npl_fuel_retail_2017-2020.xlsx", 
                                   skip = 1) %>% 
  mutate(`effective Date` = str_squish(str_extract(`effective Date`, ".*(?=\\()"))) %>% 
  mutate(date = ymd(`effective Date`)) %>% 
  select(date, diesel) %>% 
  mutate(date = yearmonth(date)) %>% 
  group_by(date) %>% 
  summarise(price = mean(diesel, na.rm = TRUE)) %>% 
  as_tsibble() %>% 
  fill_gaps()

fuel_npl_1415 <- read_csv("./data/prices_nepal/wfp_food_prices_nepal_markethubwise_nepal_2005-2019.csv", skip = 1) %>%
  filter(category == "non-food", cmname == "Fuel (diesel) - Retail") %>% 
  select(date, price, country, mktname) %>% 
  mutate(date = yearmonth(date)) %>% 
  filter(mktname %in% c("Kathmandu", "Kailali", "Rupandehi", "Parsa", "Chitwan")) %>% 
  group_by(country, date) %>% 
  summarise(price = mean(price, na.rm = TRUE)) %>% 
  as_tsibble(index = date)

fuel_price_ts <- fuel_biannual_series %>% 
  filter(date >= 2000) %>% 
  full_join(fuel_npl_1415) %>%
  full_join(fuel_npl_1719) %>% 
  select(-country_code) %>% 
  filter(date >= ymd("2000-01-01")) %>% 
  fill_gaps() %>% 
  mutate(price = imputeTS::na_interpolation(price))
```


```{r wheat-india-canada-us}
# monthly price series of wheat price canada
# wholesale_canada_usd <- readxl::read_xlsx("./data/wheat_canada_usd_metric_tons.xlsx", skip = 1)
# wholesale_canada_usd <- wholesale_canada_usd %>% 
#   transmute(date = yearmonth(Month), 
#          price = Price / 1000, 
#          country = "Canada", 
#          currency = "NRS", # series is converted 
#          cmname = "Wheat")

# the series is given for inflation adjusted currency rate
# the dollars per bushel value is in USD
# the adjustment is made for the date: Dec 31, 2019
# buying: 113.81 and selling: 114.41
wheat_canada_df <- readxl::read_xlsx("./data/wheat_canada_historical_bushel.xlsx", skip = 9) %>% 
  transmute(date = yearmonth(date), 
            price = value*50/1000*113.81) %>% # price converted to NRS
  group_by(date) %>% 
  summarise(price = mean(price, na.rm = T)) %>% 
  mutate(country = "Canada", 
            currency = "CAD",
            cmname = "Wheat")

# monthly retail price of wheat india (uttar pradesh and bihar)
retail_up <- readxl::read_xlsx("./data/wheat_retail_india_up_bihar.xlsx", "uttar_pradesh") %>% 
  transmute(date = yearmonth(date), cmname, price, currency, country, mktname)
  
retail_bihar <- readxl::read_xlsx("./data/wheat_retail_india_up_bihar.xlsx", "bihar") %>% 
  transmute(date = yearmonth(date), cmname, price, currency, country, mktname)
retail_up_bihar <- full_join(retail_up, retail_bihar) %>% 
  mutate(cmname = "Wheat", 
         date = yearmonth(date),
         price = price * 1.6)

```


```{r cost-of-production}
# annual cost of production series (producer prices), nepal and canada
cost_of_production_np_ca <- read_csv("./data/producer_price_all_crops_global_1991-2017.csv") %>% 
  filter(Area %in% c("Nepal", "Canada")) %>% 
  filter(Item %in% c("Wheat"))

cost_of_production_np_ca <- cost_of_production_np_ca %>%
  select(country = Area, cmname = Item, Element, Unit, Y1991:Y2017F)

cost_of_production_np_ca %>% 
  mutate_at(vars(Y1991:Y2017F), as.numeric) %>% 
  pivot_longer(cols = Y1991:Y2017F, names_prefix = "Y", names_to = c("Year_obs", "Year_forecast"), names_pattern = "(\\d*)([[:alpha:]]?)", values_to = c("Price_obs", "Price_forecast")) %>% 
  filter(Unit == "USD") %>% 
  filter(!is.na(Price_obs)) %>% 
  select(date = Year_obs, price = Price_obs, cmname, country) %>% 
  mutate(date = as.integer(date)) %>% 
  as_tsibble(index = date, key = c(country, cmname)) %>% 
  autoplot(.vars = price)
```


```{r wholesale-price}
# annual wholesale price, nepal (per kg of grain)
wheat_wholesale_np <- wheat_wholesale_nepal <- readxl::read_xlsx("./data/prices_nepal/cereal_wholesale_nepal.xlsx", skip = 1) %>% 
  filter(Item == "Wheat") %>% 
  select(-SN, date = `Year Code`, cmname = Item, price = Value) %>% 
  mutate(price = price/1000) # per kg
```


## Combined series

```{r price-series-all}

# price ts long format for plotting
price_ts <- retail_mhub %>% 
  mutate(country = "Nepal", 
         currency = "NPR") %>% 
  full_join(retail_up_bihar) %>% 
  full_join(wheat_canada_df) %>% 
  full_join(weather_markets_df) %>% 
  as_tsibble(index = `date`, key = c(`mktname`, `country`)) %>% 
  fill_gaps() %>% 
  mutate(country = fct_recode(country, "Five districts" = "Nepal")) %>% 
  # as_tibble() %>%
  group_by(country) %>% 
  summarise(price = mean(price, na.rm = T)) %>% 
  ungroup() %>%
  full_join(retail_pr_np_wfp %>% 
              summarise_at("price", 
                           list(~mean(., na.rm = T))) %>% 
              mutate(country = "Nepal")) %>% 
  # pivot_wider(names_from = country, values_from = price)
  filter(date > ymd("2000-01-01"))

# price and precipitation ts wide format for modeling
price_precipitaion_ts <- retail_mhub %>% 
  mutate(country = "Nepal", 
         currency = "NPR") %>% 
  full_join(retail_up_bihar) %>% 
  full_join(wheat_canada_df) %>% 
  full_join(weather_markets_df) %>% 
  as_tsibble(index = `date`, key = c(`mktname`, `country`)) %>% 
  filter(date > ymd("1995-01-01")) %>% 
  fill_gaps() %>% 
  # mutate(country = fct_recode(country, "Five districts" = "Nepal")) %>% 
  mutate(market = case_when(mktname %in% c("Chitwan", "Kathmandu") ~ "Nepal (Chitwan and Kathmandu)",
                            mktname %in% c("Kailali", "Rupandehi", "Parsa") ~ "Nepal (Kailali, Rupandehi, Parsa)", 
                            TRUE ~ country, 
                            is.na(mktname) ~ country)) %>%
  group_by(market) %>% 
  summarise(price = mean(price, na.rm = T), 
            precipitation_total = mean(PRECTOT, na.rm = T)) %>% 
  pivot_wider(names_from = market, values_from = c(price, precipitation_total)) %>% 
  mutate_if(is.numeric, list(~ifelse(is.nan(.), NA, .))) %>% 
  select(-precipitation_total_Canada, -precipitation_total_India) %>% 
  filter(date >= ymd("2001-Apr-01")) %>% 
  as_tsibble(index = date)

price_precipitaion_ts %>% 
  autoplot(.var = `precipitation_total_Nepal (Kailali, Rupandehi, Parsa)`)
price_precipitaion_ts %>% 
  autoplot(.var = `precipitation_total_Nepal (Chitwan and Kathmandu)`)

price_precipitation_fuel_ts <- price_precipitaion_ts %>% 
  full_join(fuel_price_ts %>% select(fuel_price = price)) %>% 
  janitor::clean_names()
```


```{r india-nepal-canada-price-series}
price_series_gg <- price_ts %>% 
  ggplot(aes(x = date, y = price, color = country)) +
  geom_line(size = 1.1) +
  scale_color_viridis_d(labels = c("Canada (average)", "Five districts (Kailali, \nRupandehi, Chitwan, Kathmandu, Parsa)", "Bordering Indian states (Uttar \npradesh, Bihar)", "Nepal (average)")) +
  # scale_color_discrete(labels = c("Canada (average)", "Five districts (Kailali, \nRupandehi, Chitwan, Kathmandu, Parsa)", "Bordering Indian states (Uttar \npradesh, Bihar)", "Nepal (average)")) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y", minor_breaks = NULL) +
  labs(x = "Date", y = "Mean price (Rs)") +
  ggtitle(label = "Mean price of wheat", 
          subtitle = "Aggregated over selected districts compared to national average, aggregated Indian bordering states (Uttar Pradesh and Bihar) and international dominant producer (Canada)")

# save price series graph
# ggsave("price_series_all_we_have.png", price_series_gg, 
#        device = "png", width = 14, 
#        height = 8, units = "in", dpi = 200)

```


# Geographical context of study districts

## Study districts and market centres

A map of study districts.

```{r study-districts, fig.cap="Geographical context of selected district markets", fig.width=8, out.width="95%"}
# read nepal district map
np_dist <- sf::st_read("./data/nepal_provincial/NPL_districts_poly_sd_171123.shp", quiet = T)
np_province <- sf::st_read("./data/nepal_provincial/Nepal_Province.shp", quiet = T)

np_mhub_districts <- enframe(c("Kailali", "Rupandehi", "Parsa", "Kathmandu", "Chitwan"),
                             value = "district", name = "study") %>%
  mutate(study = TRUE)

## mutate np_mhub_districts record sheet to match district names;
# so, yes only uppercasing will do the job
np_mhub_districts <- np_mhub_districts %>%
  mutate(district = str_to_upper(district))

# ggplot2 plotting
np_dist <- np_dist %>%
  mutate(DISTRICT = fct_recode(DISTRICT, "CHITWAN" = "CHITAWAN")) %>% 
  left_join(np_mhub_districts, by = c("DISTRICT" = "district"))

# transform crs of district map to EPSG "4326" (same as that of province map)
np_dist <- sf::st_transform(np_dist, crs = "+proj=longlat +datum=WGS84 +no_defs")

# seven provinces
seven_province <- np_province$State_Name

# ggplot2 plotting
five_districts_gg <- ggplot() +
  geom_sf(data = st_geometry(np_province), alpha = 1, lwd = 0.4, color = "blue") +
  geom_sf(data = st_geometry(np_dist), aes(fill = np_dist$study), lwd = 0.3, alpha = 1) +
  # geom_sf(data = st_geometry(np_districts_production),
  #         alpha = 0.2, lwd = 0.5, color = "blue", aes(fill = "wheat3")) +
  scale_fill_manual(values = c("wheat4", "green"), labels = c("Yes", "No")) +
  labs(fill = "Study performed",
       title = "Districts of which market study was performed") +
  ggrepel::geom_label_repel(data=(np_dist[!is.na(np_dist$study), ] %>%
                             mutate(lon=map_dbl(.$geometry, ~st_centroid(.x)[[1]]), # add centroid values for labels
                                    lat=map_dbl(.$geometry, ~st_centroid(.x)[[2]]))),
                           aes(x=lon, y=lat, label=DISTRICT), size = 2) + # default size is big
  guides(fill=FALSE) + # remove legend
  xlab(NULL) + ylab(NULL) +
  theme_bw() +
  theme(panel.grid.major = element_line(colour = "wheat2")) # change the grid (graticule) color
five_districts_gg

# ggsave("./outputs/nepal_province_and_geocentres_map.png",
#        plot = eight_gg, units = "in", dpi = 300, width = 10)

```


## Aggregate series summary

Joint time series plot of rice and wheat retail prices aggregated over selected districtwise markets and comparison to national average price.

```{r price-series-line-acf-plots, fig.cap="Time series plots of wheat retail price series for different markets. Progression of price series with time (Top). Autocorrelation plot for forward lags(Lower left). Seasonal trend plot over several years (Lower right)"}

# # line plot of single price series
# ggplot(retail_mhub %>% filter(mktname == "Chitwan"), 
#        aes(x = date, y = price)) + 
#   geom_line() + 
#   geom_point()
# 
# # ACF of price series (classical way)
# retail_acf <- retail_mhub %>%
#   select(-lprice) %>% 
#   named_group_split(mktname) %>%
#   map(~.x %>% fill_gaps(.full = FALSE)) %>%
#   map(~.x %>% tidyr::fill(price, .direction = "down")) %>%
#   map(~tsbox::ts_ts(.x)) %>%
#   map(~.x %>% na.omit()) %>%
#   map(~acf(.x, plot = F))
# # data is highly autocorrelated, hence it needs differencing to remove the trend.
#
# map2(.x = retail_acf, 
#       .y = names(retail_acf),
#       .f = ~.x %>% 
#         feasts::autoplot() +
#         ggtitle(paste("ACF of ", .y)))
# 
# # lag plots for single series
# feasts::gg_lag(retail_mhub %>% filter(mktname == "Chitwan"), y = price)
# 
# # season plot for single series
# feasts::gg_season(retail_mhub %>% filter(mktname == "Chitwan"), y = price)
# 
# # subseries of single series (accepts faceting, but no missing allowed)
# feasts::gg_subseries(retail_mhub %>% filter(mktname == "Chitwan"), y = price)
# # feasts::ACF() is analogous to stats::acf for autocorrelation diagnostics
# retail_mhub %>%
#   fill_gaps() %>%
#   feasts::ACF(price) %>%
#   autoplot() # plots on all series
#
# # feasts::PACF() is analogous to stats::pacf
# retail_mhub %>% 
#   fill_gaps() %>% 
#   feasts::PACF(price) %>% 
#   autoplot() # plots on all series

retail_mhub_acf <- map(.x = unique(retail_mhub$mktname), 
    .f = ~retail_mhub %>% 
      filter(mktname == .x) %>% 
      tsibble::fill_gaps() %>% 
      feasts::gg_tsdisplay() +
      ggtitle( .x))

# autocorrelation plots
# walk2(.x = map(retail_mhub_acf, 2), 
#       .y = unique(retail_mhub$mktname),
#       ~ggsave(paste("ACF_", .y, ".png", sep = ""), .x, width = 8, 
#               height = 6, units = "in", dpi = 200, device = "png"))

```

Time series plot of wheat retail price series is presented in above figures with some diagnostic plot alongside. The lineplot shows that there exist some time gaps at random periods. Autocorrelation of consecutive first order differenced lags is similarly shown.

# Linear regression model formulation for price series

```{r lm1-without-time}
# fit a lm as it is
price_lm1 <- lm(data = price_precipitation_fuel_ts, formula = price_nepal_kailali_rupandehi_parsa ~ 
                 # date + 
                 price_canada +
                 price_india +
                 price_nepal_chitwan_and_kathmandu +
                 precipitation_total_nepal_chitwan_and_kathmandu +
                 precipitation_total_nepal_kailali_rupandehi_parsa +
                 fuel_price
                 )

anova(price_lm1) %>% 
  broom::tidy() %>% 
  mutate(term = stringr::str_replace_all(term, "_", " ")) %>% 
  knitr::kable(caption = "ANOVA of regression between price of producer districts (as dependent variable) and 6 regressor variables (price of wheat in international market, price of wheat in indian bordering states, price of wheat in consumer districts, precipitation of consumer districts, precipitation of producer districts)", booktabs = TRUE, digits = 3) %>% 
  kableExtra::kable_styling(latex_options = "HOLD_position") %>% 
  kableExtra::column_spec(column = 1, width = "7em")
  

```

The regression above (Table \@ref(tab:lm1-without-time)) is obtained on fitting the model Equation \@ref(eqn:lm1).

\begin{equation}
\label{eqn:lm1}
\begin{aligned}
\begin{split}
price_{\textrm{producer districts}} &= price_{\textrm{canada}} + price_{\textrm{indian bordering states}} \\ &+
price_{\textrm{consumer districts}} + precipitation_{\textrm{producer districts}} \\ &+
precipitation_{\textrm{consumer districts}} + fuel~price_{\textrm{national average}}
\end{split}
\end{aligned}
\end{equation}

This presents a typical case of spurious relationship among variables, where variables having times series attributes show exceptionally high association among them. For example, all three aggregated wheat price series we consider in the regression (price in Canada, price in India, and price in Nepalese consumer markets) which show highly significant association. This is problematic and misleading, because without accounting for linear time trend they show very unstable variance, which increases at extremes (more recent time period). The phenomena of possible presence of heteroskedasticity is shown in the residual-vs-fit plot in Figure \@ref(fig:lm1-residual-vs-fit-plot).

```{r lm1-residual-vs-fit-plot, fig.cap="Residual (pearsons') versus fit plot of the linear regression without accounting for time attributes of the series", fig.align='center'}
car::residualPlot(price_lm1)
```

Simply after incorporating linear trend of time in the regression model (Equation \@ref(eqn:lm1)), we get a different statistic. 

\begin{equation}
\label{eqn:lm2}
\begin{aligned}
\begin{split}
price_{\textrm{producer districts}} &= date + price_{\textrm{canada}} + price_{\textrm{indian bordering states}} \\ &+
price_{\textrm{consumer districts}} + precipitation_{\textrm{producer districts}} \\ &+
precipitation_{\textrm{consumer districts}} + fuel~price_{\textrm{national average}}
\end{split}
\end{aligned}
\end{equation}

However, even then there is likely presence of biased variance, as shown in Figure \@ref(fig:lm2-residual-vs-fit-plot) which uses Equation \@ref(eqn:lm2) for model fitting. 

```{r lm2-with-time}
# fit a lm as it is with 
price_lm2 <- lm(data = price_precipitation_fuel_ts, formula = price_nepal_kailali_rupandehi_parsa ~ 
                 date +
                 price_canada +
                 price_india +
                 price_nepal_chitwan_and_kathmandu +
                 precipitation_total_nepal_chitwan_and_kathmandu +
                 precipitation_total_nepal_kailali_rupandehi_parsa +
                 fuel_price)

price_lm2_consumer <- lm(data = price_precipitation_fuel_ts, formula = price_nepal_chitwan_and_kathmandu ~ 
                           date +
                           price_canada +
                           price_india +
                           price_nepal_kailali_rupandehi_parsa +
                           precipitation_total_nepal_chitwan_and_kathmandu +
                           precipitation_total_nepal_kailali_rupandehi_parsa +
                           fuel_price)
```


```{r lm2-residual-vs-fit-plot, fig.cap="Residual (pearsons') versus fit plot of the linear regression after incorporating linear time trend of the price series", fig.align='center'}
car::residualPlot(price_lm2)
```

## Testing for heteroskedasticity

Below we test the linear model (Equation \@ref(eqn:lm2) and its counterpart with consumer districts as dependent variable and same independent variables with linear time trend) for presence of heteroskedasticity using Breusch-Pagan test. The test fits a linear regression model to the residuals of a linear regression model (by default the same explanatory variables are taken as in the main regression model) and rejects if too much of the variance is explained by the additional explanatory variables.

Breusch pagan test uses the null hypothesis of Homoscadesticity while testing studentized residuals. Hence, if the null hypothesis is rejected (p < 0.05), there is possible presence of heteroskedasticity.

```{r lm2-bptest}
map_dfr(list(price_lm2, price_lm2_consumer), 
        ~lmtest::bptest(.x) %>% 
          tidy()) %>% 
  knitr::kable(caption = "Breusch-Pagan test for heteroskedasticity of price series, modeled by the regression Equation \ref(eqn:lm2) for two domestic price series (producers districts and consumer districts)", booktabs = TRUE)
```


A possible measure to removing non-stationary trend in the series is by differencing (with `diff`). However, before progressing we confirm that justifiable lag operations can infact render the series free of trends. For this, two popular unit test routines are performed -- Augmented Dickey-Fueller test and KPSS test.

# Unit root testing

## Unit root (ADF and KPSS) test of retail price

The ADF, available in the function `adf.test()` (in the package `tseries`) implements the t-test of $H_0: \gamma = 0$ in the regression, below.

\begin{equation}
\label{eqn:lagged-ts-regression}
  \Delta {{Y}_{t}}={{\beta
  }_{1}}+{{\beta }_{2}}t+\gamma {{Y}_{t-1}}+ \sum\limits_{i=1}^{m}{\delta_i \Delta
    {{Y}_{t-i}}+{{\varepsilon }_{t}}}
\end{equation}
  
The null is therefore that x has a unit root. If only x has a non-unit root, then the x is stationary (rejection of null hypothesis).

```{r adf-kpss-test-retail, results='asis'}
# price series are log transformed to stabilize the variance
ppf_ts_log <- price_precipitation_fuel_ts %>% 
  mutate_at(vars(contains("price")), list(~(log(.))))

# adf test for major citywise series
stationary_series <- ppf_ts_log %>% 
  as_tibble() %>% # doesn't work with tsibble
  summarise_at(vars(contains("price")), list(adf = ~list(tseries::adf.test(na.omit(.))), 
                                             kpss = ~list(tseries::kpss.test(na.omit(.))))) %>% 
  pivot_longer(cols = everything(), 
               names_pattern = "(.*)_(adf|kpss)", 
               names_to = c("series", "test"), 
               values_to = "hypothesis") %>% 
  mutate(lprice_pvalue = map_dbl(hypothesis, ~.x[["p.value"]]), 
         lprice_tstatistic = map_dbl(hypothesis, ~.x[['statistic']]), 
         lprice_null_accepted = lprice_pvalue > 0.05)

stationary_series %>% 
  select(-hypothesis) %>% 
  mutate(series = stringr::str_replace_all(series, "_", " ")) %>% 
  rename_all(function(x)stringr::str_replace_all(x, "_", " ")) %>% 
  knitr::kable(caption = "Unit root test of log(price) series variables (both dependent and independent)", 
               booktabs = TRUE, digits = 2) %>% 
  kableExtra::column_spec(column = 1, width = "8em")
```

The ADF test was parametrized with the alternative hypothesis of stationarity. This extends to following assumption in the model parameters;

$$
-2 \leq \gamma \leq 0\ \text{or } (-1 < 1+\phi < 1)
$$

`k` in the function refers to the number of $\delta$ lags, i.e., $1, 2, 3, ...., m$ in the model equation. 

The number of lags `k` defaults to `trunc((length(x)-1)^(1/3))`, where `x` is the series being tested. The default value of `k` corresponds to the suggested upper bound on the rate at which the number of lags, `k`, should be made to grow with the sample size for the general ARMA(p,q) setup `citation(package = "tseries")`.

For a Dickey-Fueller test, so only up to AR(1) time dependency in our stationary process, we set `k = 0`. Hence we have no $\delta$s (lags) in our test.

The DF model can be written as:

$$
Y_t = \beta_1 + \beta_2 t + \phi Y_{t-1} + \varepsilon_t
$$

It can be re-written so we can do a linear regression of $\Delta Y_t$ against $t$ and $Y_{t-1}$ and test if $\phi$ is different from 0. If only, $\phi$ is not zero and assumption above ($-1 < 1+\phi < 1$) holds, the process is stationary. If $\phi$ is straight up 0, then we have a random walk process -- all white noise.

$$
\Delta {Y}_{t}=\beta_1+\beta_2 t+\gamma {Y}_{t-1} + \varepsilon_{t}
$$

Alternative to above discussed tests, the Phillips-Perron test with its nonparametric correction for autocorrelation (essentially employing a HAC estimate of the long-run variance in a Dickey-Fuller-type test instead of parametric decorrelation) may be used. It is available in the function `pp.test()`.

## Unit root test based lag order differencing determination

An alternative to decomposition for removing trends is differencing [@woodward2017applied]. We define the difference operator as,

\begin{equation}
\nabla x_t = x_t - x_{t-1},
\label{eqn:difference-operator}
\end{equation}

and, more generally, for order $d$

\begin{equation}
\nabla^d x_t = (1-\mathbf{B})^d x_t,
\label{eqn:order-d-difference-operator}
\end{equation}

Where $\mathbf{B}$ is the backshift operator (i.e., $\mathbf{B}^k x_t = x_{t-k}$ for $k \geq 1$).

Applying the difference to a random walk, the most simple and widely used time series model, will yield a time series of Gaussian white noise errors $\{w_t\}$:

\begin{equation}
  \begin{aligned}
    \nabla (x_t &= x_{t-1} + w_t) \\
    x_t - x_{t-1} &= x_{t-1} - x_{t-1} + w_t \\
    x_t - x_{t-1} &= w_t
  \end{aligned}
  \label{eqn:random-walk-series}
\end{equation}

We use an implementation of time series differencing based on optimal lag length in order to render series stationary. The first lag order differenced log(price) series (derived based on "kpss" test statistic) is shown in Figure \@ref(fig:differenced-series-kpss-lag). The kpss test, however, determined the precipitation series to be integrated of order null. This is due to insensitivity of test (model) to seasonal lag component, which is infact nicely captured by addtive or multiplicative trend decomposition (discussed ahead).

```{r old-multivariate-price-series}
# multivariate price series
ppf_ts_log_box <- tsbox::ts_ts(ppf_ts_log)
colnames(ppf_ts_log_box) <- c("lp_canada", "lp_india", "lp_npl_ck", "lp_npl_krp", "precip_npl_ck", "precip_npl_krp", "lp_fuel")
# ppf_ts_log_box %>% plot()
```


```{r differenced-series-kpss-lag, fig.cap="Plot of differenced time series for various lag length determined by kpss statistic."}

diff(ppf_ts_log_box[, c(1:4,7)], lag = ndiffs(ppf_ts_log_box, test = "kpss", type = "trend")) %>% 
  plot()
```

The first order differencing of price renders series stationary. However, precipitation series shows distinct components. Here, a linear model is fitted to the trend component, decomposed (into seasonal and trend components) from two precipitation series (producer and consumer districts), along with other terms of Equation \@ref(eqn:lm2) and the ANOVA output is presented.

```{r lm3-seasonality-removal-precipitation}
# remove seasonality of precipitation and fit model
precipitation_total_krp_trend <- decompose(price_precipitation_fuel_ts %>%
            select(precipitation_total_nepal_kailali_rupandehi_parsa) %>%
            tsbox::ts_ts(), type = "multiplicative") %>%
  .[["trend"]]

precipitation_total_ck_trend <- decompose(price_precipitation_fuel_ts %>%
            select(precipitation_total_nepal_chitwan_and_kathmandu) %>%
            tsbox::ts_ts(), type = "multiplicative") %>%
  .[["trend"]]

```

```{r anova-producer-market}

lm(data = price_precipitation_fuel_ts %>%
                  bind_cols(precipitation_total_krp_trend = precipitation_total_krp_trend,
                            precipitation_total_ck_trend = precipitation_total_ck_trend),
                formula = price_nepal_kailali_rupandehi_parsa ~
                 date +
                 price_canada +
                 price_india +
                 price_nepal_chitwan_and_kathmandu +
                 precipitation_total_ck_trend +
                 precipitation_total_krp_trend +
                 fuel_price
                 ) %>% 
  anova() %>% 
  broom::tidy() %>% 
  knitr::kable(caption = "ANOVA of linear model fit with trend component of precipitation series with price(producer market) as dependent variable.", booktabs = TRUE, digits = 2)

```


```{r anova-consumer-market}
lm(data = price_precipitation_fuel_ts %>%
     bind_cols(precipitation_total_krp_trend = precipitation_total_krp_trend,
               precipitation_total_ck_trend = precipitation_total_ck_trend),
   formula = price_nepal_chitwan_and_kathmandu ~
     date +
     price_canada +
     price_india + price_nepal_kailali_rupandehi_parsa +
     precipitation_total_ck_trend +
     precipitation_total_krp_trend +
     fuel_price
) %>% 
  anova() %>% 
  broom::tidy() %>% 
  knitr::kable(caption = "ANOVA of linear model fit with trend component of precipitation series with price(consumer market) as dependent variable.", booktabs = TRUE, digits = 2)

```

# VAR model

## VAR

VAR is a system regression model, i.e., there are more than one dependent variable. The regression is defined by a set of linear dynamic equations where each variable is specified as a function of an equal number of lags of itself and all other variables in the system. Any additional variable, adds to the modeling complexity by increasing an extra equation to be estimated.

The vector autoregression (VAR) model extends the idea of univariate autoregression to $k$ time series regressions, where the lagged values of *all* $k$ series appear as regressors. Put differently, in a VAR model we regress a *vector* of time series variables on lagged vectors of these variables. As for $AR(p)$ models, the lag order is denoted by $p$ so the $VAR(p)$ model of two variables $X_t$ and $Y_t$ ($k=2$) is given by a vector of equations (Equation \@ref(eqn:vector-regression-ts)).

\begin{equation}
\label{eqn:vector-regression-ts}
\begin{split}
\begin{aligned}
  Y_t =& \, \beta_{10} + \beta_{11} Y_{t-1} + \dots + \beta_{1p} Y_{t-p} + \gamma_{11} X_{t-1} + \dots + \gamma_{1p} X_{t-p} + u_{1t}, \\
  X_t =& \, \beta_{20} + \beta_{21} Y_{t-1} + \dots + \beta_{2p} Y_{t-p} + \gamma_{21} X_{t-1} + \dots + \gamma_{2p} X_{t-p} + u_{2t}.
\end{aligned}
\end{split}
\end{equation}

The $\beta$s and $\gamma$s can be estimated using OLS on each equation.

Simplifying this to a bivariate $VAR(1)$, we can write the model in matrix form as:

\begin{equation}
\label{eqn:matix-var1-model}
Y_t = \beta_0 + \beta_1 Y_{t-1} + \mu_t
\end{equation}

Where,

- $Y_t, Y_{t-1}$ and $\mu_t$ are (2 x 1) column vectors
- $\beta_0$ is a (2 x 1) column vector
- $\beta_1$ is a (2 x 2) matrix


also,


$$
Y_t = 
\begin{pmatrix} 
y_{1t} \\
y_{2t}
\end{pmatrix},\ 
Y_{t-1} = 
\begin{pmatrix} 
y_{1t-1} \\
y_{2t-1}
\end{pmatrix}
$$




$$
\mu_t = 
\begin{pmatrix} 
\mu_{1t} \\
\mu_{2t}
\end{pmatrix},
\beta_{0} = 
\begin{pmatrix} 
\beta_{10} \\
\beta_{20}
\end{pmatrix},
\beta_{1} = 
\begin{pmatrix} 
\beta_{11} & \alpha_{11} \\
\alpha_{21} & \beta_{21}
\end{pmatrix}
$$


It is straightforward to estimate VAR models in `R`. A feasible approach is to simply use `lm()` for estimation of the individual equations. Furthermore, the `vars` package provides standard tools for estimation, diagnostic testing and prediction using this type of models.

Only when the assumptions presented below hold, the OLS estimators of the VAR coefficients are consistent and jointly normal in large samples so that the usual inferential methods such as confidence intervals and $t$-statistics can be used [@metcalfe2009introductory].

Two series $w_{x,t}$ and $w_{y,t}$ are bivariate white noise if they are stationary and their cross-covariances $\gamma_{xy}(k) = Cov(w_{x,t}, w_{y, t+k})$ satisfies

$$
\gamma_{xx}(k) = \gamma_{yy}(k) = \gamma_{xy}(k) = 0\ \text{for all } k \neq 0
$$


The parameters of a var(p) model can be estimated using the `ar` function in `R`, which selects a best-fitting order $p$ based on the smallest information criterion values. 

<!-- ```{r var-simulation} -->
<!-- # simulated bivariate white noise process of ... and the parameters from the stationary VAR(1) model: -->

<!-- library(mvtnorm) -->
<!-- cov.mat <- matrix(c(1, 0.8, 0.8, 1), nr = 2) -->
<!-- w <- rmvnorm(1000, sigma = cov.mat) -->
<!-- cov(w) -->

<!-- wx <- w[, 1] -->
<!-- wy <- w[, 2] -->
<!-- ccf(wx, wy, main = "") -->

<!-- par_var1_m1 <- matrix(c(0.4, 0.2, 0.3, 0.1), nrow = 2) -->

<!-- par_var1_m1 -->

<!-- # The absolute value of roots of the equation is given by: -->

<!-- determinant_var1 <- function(x) { -->
<!--   # x A matrix of parameter \phi -->
<!--   c(1, -(x[1,1] + x[2,2]), -(-x[1,1]*x[2,2] + x[1,2]*x[2,1])) -->
<!-- } -->

<!-- Mod(polyroot(determinant_var1(par_var1_m1))) -->

<!-- # a VAR(1) process is simulated below and the parameters from the simulated series estimated using ar. -->

<!-- x <- y <- rep(0, 1000) -->

<!-- x[1] <- wx[1] -->
<!-- y[1] <- wy[1] -->

<!-- for (i in 2:1000) { -->
<!--   x[i] <- par_var1_m1[1,1] * x[i-1] + par_var1_m1[1,2]*y[i-1] + wx[i] -->
<!--   y[i] <- par_var1_m1[2,1] * x[i-1] + par_var1_m1[2,2]*y[i-1] + wy[i] -->
<!-- } -->

<!-- xy.ar <- ar(cbind(x, y)) -->
<!-- xy.ar$ar[, , ] -->

<!-- # As expected, the parameter estimates are close to the underlying model values. If the simulation is repeated many times with different realizations of the bivariate white noise, the sampling distribution of the esimators of the parameters in the model can be approximated by the histograms of the estimates together with the correlations between estimates. This is the principle used to construct bootstrap confidence intervals for model parameters when they have been estimated from time series. -->
<!-- ``` -->

The structure of VARs also allows to jointly test restrictions across multiple equations. For instance, it may be of interest to test whether the coefficients on all regressors of the lag $p$ are zero. This corresponds to testing the null that the lag order $p-1$ is correct. Large sample joint normality of the coefficient estimates is convenient because it implies that we may simply use an $F$-test for this testing problem. The explicit formula for such a test statistic is rather complicated but fortunately such computations are easily done using the `ttcode("R")` functions we work with in this chapter. Just as in the case of a single equation, for a multiple equation model we choose the specification which has the smallest $BIC(p)$, where 

$$
\begin{aligned}
  BIC(p) =& \, \log\left[\text{det}(\widehat{\Sigma}_u)\right] + k(kp+1) \frac{\log(T)}{T}.
\end{aligned}
$$

with $\widehat{\Sigma}_u$ denoting the estimate of the $k \times k$ covariance matrix of the VAR errors and $\text{det}(\cdot)$ denotes the determinant. 

As for univariate distributed lag models, one should think carefully about variables to include in a VAR, as adding unrelated variables reduces the forecast accuracy by increasing the estimation error. This is particularly important because the number of parameters to be estimated grows qudratically to the number of variables modeled by the VAR.

<!-- ```{r retail-var-fitt-oldstyle} -->

<!-- # # # Multivariate VAR (with 7 variables, i.e., markets) with lag order 1 -->
<!-- # rice -->
<!-- retail_mhub_var_rice <- retail_mhub_filled %>%  -->
<!--   select(cmname:lprice, -price, -admname) %>% -->
<!--   filter(cmname == "Rice - Retail") %>%  -->
<!--   tsbox::ts_ts() %>%  -->
<!--   na.omit() %>%  -->
<!--   vars::VAR(p = 1, ic = "SC", type = "const", lag.max = 2) -->

<!-- # wheat -->
<!-- retail_mhub_var_wheat <- retail_mhub_filled %>%  -->
<!--   select(cmname:lprice, -price, -admname) %>% -->
<!--   filter(cmname == "Wheat - Retail") %>%  -->
<!--   tsbox::ts_ts() %>%  -->
<!--   na.omit() %>%  -->
<!--   vars::VAR(p = 1, ic = "SC", type = "const", lag.max = 2) -->
<!-- ``` -->

<!-- ```{r retail-var-summary-old-style} -->

<!-- # rice summary -->
<!-- retail_mhub_var_rice %>% -->
<!--   summary() -->
<!-- # districtwise residual vs fit plots with acf and pacf -->
<!-- # plot(retail_mhub_var_rice) -->

<!-- # wheat summary -->
<!-- retail_mhub_var_wheat %>% -->
<!--   summary() -->
<!-- # districtwise residual vs fit plot with acf and pacf -->
<!-- # plot(retail_mhub_var_wheat) -->

<!-- # # # model dissection -->
<!-- # each var model is a list of linear model objects -->

<!-- # inspect individual model and check terms for significant effects -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Kathmandu %>% broom::tidy() -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Kathmandu %>% coefplot::coefplot() -->
<!-- # this suggests that retail price of rice in kathmandu are strongly associated with its retail price in the same district during previous month. -->

<!-- retail_mhub_var_rice$varresult$Rice...Retail_Parsa %>% coefplot::coefplot() -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Morang %>% coefplot::coefplot() -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Kailali %>% coefplot::coefplot() -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Banke %>% coefplot::coefplot() -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Kaski %>% coefplot::coefplot() -->
<!-- retail_mhub_var_rice$varresult$Rice...Retail_Rupandehi %>% coefplot::coefplot() -->
<!-- ``` -->


```{r retail-var-fit-tidy, results='asis'}
# # # # tidy VAR model fitting

ppf_ts_log <- ppf_ts_log %>% 
  rename(lp_canada = price_canada, lp_india = price_india, 
         lp_npl_ck = price_nepal_chitwan_and_kathmandu, 
         lp_npl_krp = price_nepal_kailali_rupandehi_parsa, 
         precip_npl_ck = precipitation_total_nepal_chitwan_and_kathmandu, 
         precip_npl_krp = precipitation_total_nepal_kailali_rupandehi_parsa, 
         lp_fuel = fuel_price)

  
ppf_ar1_var_fit <- ppf_ts_log %>%
  fill_gaps() %>%
  imputeTS::na_interpolation() %>% 
  model(var_fit = VAR(vars(lp_npl_ck, lp_npl_krp) ~ AR(p = 1) + 
                        lp_canada + 
                        lp_india + 
                        precip_npl_ck +
                        precip_npl_krp +
                        lp_fuel)) # fit AR1 model
  
# map(ppf_ar1_var_fit$var_fit, ~.x %>% glance()) %>% 
#   map_dfr(bind_rows) %>% 
#   knitr::kable(caption = "Model performance indicators of VAR(AR(1)) model for wheat log(price) series with two domestic (producer and consumer) markets as endogeneous variables and other price series, precipitation and fuel series as exogeneous regressors.", booktabs = TRUE, longtable = TRUE, digits = 3)
  
ppf_ar1_var_fit$var_fit[[1]] %>% 
  broom::tidy() %>% 
  knitr::kable(caption = "Model coefficients of VAR(AR(1)) model for for wheat log(price) series with two domestic (producer and consumer) markets as endogeneous variables and other price series, precipitation and fuel series as exogeneous regressors.", booktabs = T, longtable = TRUE, digits = 3)

```


<!-- ## Tidy VAR fitting -->

<!-- ```{r} -->
<!-- cbind(mdeaths, fdeaths) %>% as_tsibble(pivot_longer = F) %>% model(VAR(vars(log(mdeaths), fdeaths)~AR(3))) %>% report() -->
<!-- ``` -->

<!-- # Annual wholesale price of major food commodities -->

<!-- Annual average wholesale price of Barley, Buckwheat, Maize, Millet, Rice/paddy and Wheat since 1991 through 2017 (27 years). -->

<!-- ```{r food-wholesale, results='asis'} -->
<!-- food_wholesale_np <- readxl::read_xlsx("./data/prices_nepal/cereal_wholesale_nepal.xlsx", skip = 1) %>%  -->
<!--   mutate(year = `Year Code`) %>%  -->
<!--   dplyr::select(-`Year Code`, -SN) %>%  -->
<!--   as_tsibble(index = `year`, key = `Item`) -->

<!-- food_wholesale_np_table <- food_wholesale_np %>% -->
<!--   as_tibble() %>%  -->
<!--   na.omit() %>% -->
<!--   # count(Item) %>% # this is balanced for number of years -->
<!--   mutate(break_grp = as.numeric(cut_number(1:NROW(.), n = 3))) %>%  -->
<!--   group_split(break_grp) %>%  -->
<!--   # bind_cols() # because number of rows is not multiple -->
<!--   map(~select(.x, -starts_with("break"))) %>%  -->
<!--   map(~.x %>% knitr::kable(caption = "Wholesale price data of major food commodities of Nepal since 1991", booktabs = T, longtable = TRUE)) -->

<!-- walk(food_wholesale_np_table, print) -->
<!-- ``` -->

<!-- # Import historical rice and wheat data -->

<!-- Retail price of various rice commodities and wheat flour since 1976 AD. -->

<!-- ```{r rice-wheat-historical-annual-series} -->

<!-- cmname_file <- list.files(path = "./data", pattern = "npl_nepalindata_", full.names = T) -->
<!-- cmname_list <- map(cmname_file, ~read_csv(.x, skip = 1)) -->

<!-- historical_pr_rice_wheat <- cmname_list %>%  -->
<!--   map(~(t(.x)[-1,])) %>%  -->
<!--   map_dfr(~as_tibble(.x, rownames = "year", .name_repair = ~ c("cmname", "price"))) %>%  -->
<!--   mutate(year = yearmonth(year),  -->
<!--          price = as.numeric(price)) -->

<!-- historical_pr_rice_wheat %>%  -->
<!--   ggplot(aes(x = year, y = price, color = cmname)) + -->
<!--   geom_line() + -->
<!--   scale_color_viridis_d() + -->
<!--   # facet_grid(~cmname) -->
<!--   guides(color = guide_legend(label.position = "left", direction = "vertical",  -->
<!--                               title.hjust = 0.5, title = "Commodity", -->
<!--                               ncol = 1, size = 8, keywidth = 1, keyheight = 1)) -->

<!-- ``` -->

<!-- ## Causality test -->

<!-- Causality test is VAR based approach to explain cause-effect relationship among endogenous variables. However, the Granger-causality [@granger1988causality] inference does not, of course, establish the real causation phenomena. If one of the variables is sufficiently correlated to the other so that forecast of former depends on the later to a considerable extent, then the first variable is *granger-caused* by the second one. -->

<!-- The Granger causality has been briefed to be useable test in certain cases of two series violating the stationarity assumption^[https://davegiles.blogspot.com/2011/04/testing-for-granger-causality.html]. @papana2014identifying state that GC test can only to applied if both the series are stationary^[[Mindy Mallory's blog article also suggests that series be stationary](http://blog.mindymallory.com/2018/02/basic-time-series-analysis-the-var-model-explained/)]. Same paper also cautioned that VAR(1) models of cointegrated endogenous series will fail to capture long-run relationships. Therefore, the authors suggest surplus lag Granger-causality test be used if the series are a nonstationary data. -->

<!-- Below are the results of GC test showing consequences of using both stationarity and non stationary data, with bootstrapped confidence intervals. -->

<!-- ### Case I: GC test on undifferenced log(price) series -->

<!-- ```{r gc-test-undifferenced-series} -->

<!-- # # # Multivariate VAR (with 7 variables, i.e., markets) with lag order 1 --> -->
<!-- # rice -->
<!-- retail_mhub_var_rice_data <- retail_mhub_filled %>%  -->
<!--   select(cmname:lprice, -price, -admname) %>% -->
<!--   filter(cmname == "Rice - Retail") %>% -->
<!--   tsbox::ts_ts() %>%  -->
<!--   na.omit() -->

<!-- colnames(retail_mhub_var_rice_data) <- c("kathmandu", "parsa", "morang", "kailali", "banke", "kaski", "rupandehi") -->

<!-- retail_mhub_var_rice <- retail_mhub_var_rice_data %>%  -->
<!--   vars::VAR(p = 1, ic = "SC", type = "const", lag.max = 2) -->

<!-- # wheat -->
<!-- retail_mhub_var_wheat_data <- retail_mhub_filled %>% -->
<!--   select(cmname:lprice, -price, -admname) %>% -->
<!--   filter(cmname == "Wheat - Retail") %>%  -->
<!--   tsbox::ts_ts() %>%  -->
<!--   na.omit() -->

<!-- colnames(retail_mhub_var_wheat_data) <- c("kathmandu", "parsa", "morang", "kailali", "banke", "kaski", "rupandehi") -->

<!-- retail_mhub_var_wheat <- retail_mhub_var_wheat_data %>%  -->
<!--   vars::VAR(p = 1, ic = "SC", type = "const", lag.max = 2) -->

<!-- # # Rice -->
<!-- # Does log(price) of respective markets Granger-cause log(price) change of other markets -->
<!-- gc_boot_rice   <- map_df(.x = colnames(retail_mhub_var_rice_data), -->
<!--                     .f = ~vars::causality(retail_mhub_var_rice, cause = .x, boot = TRUE, boot.runs = 5000)$Granger %>% tidy() -->
<!-- ) -->

<!-- gc_boot_rice %>%  -->
<!--   knitr::kable(caption = "Granger causality test of multivariate (7 market series) var models of Rice log(price) series", booktabs = T, digits = 3) %>% -->
<!--   kableExtra::kable_styling(latex_options = "HOLD_position") %>%  -->
<!--   kableExtra::column_spec(1:4, width = c("3em", "3em", "3em", "20em")) -->

<!-- # # Wheat -->
<!-- # Does log(price) of respective markets Granger-cause log(price) change of other markets -->
<!-- gc_boot_wheat   <- map_df(.x = colnames(retail_mhub_var_wheat_data), -->
<!--                     .f = ~vars::causality(retail_mhub_var_wheat, cause = .x, boot = TRUE, boot.runs = 5000)$Granger %>% tidy() -->
<!-- ) -->

<!-- gc_boot_wheat %>%  -->
<!--   knitr::kable(caption = "Granger causality test of multivariate (7 market series) var models of Wheat log(price) series", booktabs = T, digits = 3) %>% -->
<!--   kableExtra::kable_styling(latex_options = "HOLD_position") %>%  -->
<!--   kableExtra::column_spec(1:4, width = c("3em", "3em", "3em", "20em")) -->

<!-- ``` -->


<!-- ### Case II: GC test on differenced log(price) series -->

<!-- ```{r gc-test-differenced-series} -->

<!-- # # # Multivariate VAR (with 7 variables, i.e., markets) with lag order 1 --> -->
<!-- # rice -->
<!-- retail_mhub_var_rice_data_diff <- retail_mhub_filled %>%  -->
<!--   select(cmname, mktname, date, lprice_diff) %>% -->
<!--   filter(cmname == "Rice - Retail") %>% -->
<!--   tsbox::ts_ts() %>%  -->
<!--   na.omit() -->

<!-- colnames(retail_mhub_var_rice_data_diff) <- c("kathmandu", "parsa", "morang", "kailali", "banke", "kaski", "rupandehi") -->

<!-- retail_mhub_var_rice_diff <- retail_mhub_var_rice_data_diff %>%  -->
<!--   vars::VAR(p = 1, ic = "SC", type = "const", lag.max = 2) -->

<!-- # wheat -->
<!-- retail_mhub_var_wheat_data_diff <- retail_mhub_filled %>% -->
<!--   select(cmname, mktname, date, lprice_diff) %>% -->
<!--   filter(cmname == "Wheat - Retail") %>%  -->
<!--   tsbox::ts_ts() %>%  -->
<!--   na.omit() -->

<!-- colnames(retail_mhub_var_wheat_data_diff) <- c("kathmandu", "parsa", "morang", "kailali", "banke", "kaski", "rupandehi") -->

<!-- retail_mhub_var_wheat_diff <- retail_mhub_var_wheat_data_diff %>%  -->
<!--   vars::VAR(p = 1, ic = "SC", type = "const", lag.max = 2) -->

<!-- # # Rice -->
<!-- # Does log(price) of respective markets Granger-cause log(price) change of other markets -->
<!-- gc_boot_rice_diff   <- map_df(.x = colnames(retail_mhub_var_rice_data_diff), -->
<!--                     .f = ~vars::causality(retail_mhub_var_rice_diff, cause = .x, boot = TRUE, boot.runs = 5000)$Granger %>% tidy() -->
<!-- ) -->

<!-- gc_boot_rice_diff %>%  -->
<!--   knitr::kable(caption = "Granger causality test of multivariate (7 market series) var models of Rice first order differenced log(price) series", booktabs = T, digits = 3) %>% -->
<!--   kableExtra::kable_styling(latex_options = "HOLD_position") %>%  -->
<!--   kableExtra::column_spec(1:4, width = c("3em", "3em", "3em", "20em")) -->

<!-- # # Wheat -->
<!-- # Does log(price) of respective markets Granger-cause log(price) change of other markets -->
<!-- gc_boot_wheat_diff   <- map_df(.x = colnames(retail_mhub_var_wheat_data_diff), -->
<!--                     .f = ~vars::causality(retail_mhub_var_wheat_diff, cause = .x, boot = TRUE, boot.runs = 5000)$Granger %>% tidy() -->
<!-- ) -->

<!-- gc_boot_wheat_diff %>%  -->
<!--   knitr::kable(caption = "Granger causality test of multivariate (7 market series) var models of Wheat first order differenced log(price) series", booktabs = T, digits = 3) %>% -->
<!--   kableExtra::kable_styling(latex_options = "HOLD_position") %>%  -->
<!--   kableExtra::column_spec(1:4, width = c("3em", "3em", "3em", "20em")) -->

<!-- ``` -->


<!-- # Cointegration -->

<!-- ## Residual based -->

<!-- Since the food commodities are spatially linked, more of so because they occupy the same domestic market, it is obvious that factor affecting price of one inevitably affects other, especially that of same crop in a nearby market. Having evidence for nonstationarity, it is of interest to test for a common nonstationary component by means of a cointegration test (Non-stationarity is more valid for development regionwise price series). -->

<!-- A two step method proposed by @hylleberg1990seasonal can be used to test for cointegration. -->

<!-- The procedure simply regressess one series on the other and performs a unit root test on the residuals. This test is often named after @phillips1990asymptotic. Specifically, `po.test()` performs a Phillips-Perron test using an auxiliary regression without a constant and linear trend and the Newey-West estimator for the required long-run variance. -->

<!-- The test computes the Phillips-Ouliaris test for the null hypothesis that series is not cointegrated [@R-tseries]. -->

<!-- We check the rice retail price series for all combination major districtwise markets. -->

<!-- ```{r series-mktname-wise-cname} -->
<!-- retail_mhub_cmwise <- retail_pr_np_wfp %>%  -->
<!--   group_by(cmname, mktname) %>%  -->
<!--   summarise(lprice = log(mean(price, na.rm = T))) %>%  -->
<!--   ungroup() %>%  -->
<!--   group_split(cmname) %>%  -->
<!--   set_names(c("rice", "wheat")) %>%  -->
<!--   map(~fill_gaps(.x, .full = FALSE) %>%  -->
<!--         tidyr::fill(lprice, .direction = "down")) -->
<!-- ``` -->


<!-- ```{r pairwise-phillips-cointegration} -->
<!-- # need to perform pairwise cointegration tests -->
<!-- # philip-oularis test -->
<!-- # we map to simultaneously test in different commodities (rice and wheat) -->
<!-- pairwise_series_name <- combn(c("Morang", "Parsa", "Kathmandu", "Kaski", "Rupandehi", "Banke", "Kailali"), 2) %>%  -->
<!--   t() -->

<!-- # rice series -->
<!-- rice_series_combination <- map2(pairwise_series_name[,1], -->
<!--      pairwise_series_name[,2], -->
<!--     ~tsbox::ts_ts(filter(retail_mhub_cmwise[[1]], mktname %in% c(.x, .y)))) -->

<!-- # # po test results aren't symmetric for same series done in different order -->
<!-- rice_series_combination_po_test <- map(rice_series_combination, ~tseries::po.test(.x[, 1:2])) %>%  -->
<!--   set_names(unite(as_tibble(pairwise_series_name), col = "single_col", sep = "-")$`single_col`) -->

<!-- # wheat series -->
<!-- wheat_series_combination <- map2(pairwise_series_name[,1], -->
<!--      pairwise_series_name[,2], -->
<!--     ~tsbox::ts_ts(filter(retail_mhub_cmwise[[2]], mktname %in% c(.x, .y)))) -->

<!-- # # po test results aren't symmetric for same series done in different order -->
<!-- wheat_series_combination_po_test <- map(wheat_series_combination, ~tseries::po.test(.x[, 1:2])) %>%  -->
<!--   set_names(unite(as_tibble(pairwise_series_name), col = "single_col", sep = "-")$`single_col`) -->

<!-- rice_cointegration_pair <- rice_series_combination_po_test %>% map_df(~ list(p_value = .x[["p.value"]],  -->
<!--                                                   statistic = .x[["statistic"]]), .id = "combination") -->
<!-- wheat_cointegration_pair <- wheat_series_combination_po_test %>% map_df(~ list(p_value = .x[["p.value"]],  -->
<!--                                                   statistic = .x[["statistic"]]), .id = "combination") -->

<!-- rice_cointegration_pair %>% -->
<!--   knitr::kable(caption = "Phillips-Ouliaris cointegration test for Rice log(price) series of selected district markethubs", booktabs = T, longtable = T, digits = 3) -->

<!-- wheat_cointegration_pair %>%  -->
<!--   knitr::kable(caption = "Phillips-Ouliaris cointegration test for Wheat log(price) series of selected district markethubs", booktabs = T, longtable = T, digits = 3) -->
<!-- ``` -->

<!-- Note `po.test` does not handle missing values, so we fix them through imputation. It is implemented through `tidyr::fill(..., .direction = "down")`. -->

<!-- The test suggests that all series (Both that of wheat and rice) are cointegrated for selected pairwise combination of district markets. -->

<!-- The problem with this approach is that it treats both series in an asymmetric fashion, while the concept of cointegration demands that the treatment be symmetric. -->

<!-- The po.test() function is testing the cointegration with Phillip’s Z_alpha test, which is the second residual-based test described by @phillips1990asymptotic. Because the po.test() will use the series at the first position to derive the residual used in the test, results would be determined by the series on the most left-hand side^[https://www.r-craft.org/r-news/phillips-ouliaris-test-for-cointegration/]. -->

<!-- The Phillips-Ouliaris test implemented in the `ca.po()` function from the urca package is different. In the `ca.po()` function, there are two cointegration tests implemented, namely “Pu” and “Pz” tests. Although both the `ca.po()` function and the po.test() function are supposed to do the Phillips-Ouliaris test，outcomes from both functions are completely different. -->

<!-- Similar to Phillip’s Z_alpha test, the Pu test also is not invariant to the position of each series and therefore would give different outcomes based upon the series on the most left-hand side. On the contrary, the multivariate trace statistic of Pz test has its appeal in that the outcome won’t change by the position of each series. -->

<!-- ## VAR based -->

<!-- The standard tests proceeding in a symmetric manner stem from Johansen's full-information maximum likelihood approach [@johansen1991estimation]. -->

<!-- A general vector autoregressive model is similar to the AR(p) model except that each quantity is vector valued and matrices are used as the coefficients. The general form of the VAR(p) model, without drift, is given by: -->

<!-- \begin{equation} -->
<!-- \label{eqn:var-general} -->
<!-- {\bf y_t} = {\bf \mu} + A_1 {\bf y_{t-1}} + \ldots + A_j {\bf y_{t-j}} + {\bf \varepsilon_t}  -->
<!-- \end{equation} -->

<!-- Where ${\bf \mu}$ is the vector-valued mean of the series, $A_i$ are the coefficient matrices for each lag and ${\bf \varepsilon_t}$ is a multivariate Gaussian noise term with mean zero. -->

<!-- At this stage we can form a Vector Error Correction Model (VECM) by differencing the series (Equation \@ref(eqn:vecm-differenced)). -->

<!-- \begin{equation} -->
<!-- \label{eqn:vecm-differenced} -->
<!-- \Delta {\bf y_t} = {\bf \mu} + A {\bf y_{t-1}} + \Gamma_1 \Delta {\bf y_{t-1}} + \ldots + \Gamma_j \Delta {\bf y_{t-j}} + {\bf \varepsilon_t}  -->
<!-- \end{equation} -->

<!-- Where $\Delta {\bf y_t} = {\bf y_t} - {\bf y_{t-1}}$ is the differencing operator, $A$ is the coefficient matrix for the first lag and $\Gamma_i$ are the matrices for each differenced lag. -->

<!-- For a $p^{th}$ -order cointegrated vector autoregressive (VAR) model, the error correction form is (omitting deterministic components; both no intercept or trend in either cointegrating equation or test var), we may rewrite the VAR in the form of Equation \@ref(eqn:johansens) [@johansen1991estimation]. -->

<!-- <!-- For more information refer to:  --> -->
<!-- <!-- - [Eviews documentation](./literatures/johansen_cointegration_eviews.pdf)  --> -->
<!-- <!-- - [Quantstart post](./literatures/johansen_cointegration_quantstart.pdf) --> -->
<!-- <!-- - [Kevin kotze's post](./literatures/johansen_cointegration_kevin_kotze.pdf) --> -->

<!-- <!-- equation labeling trick: https://stackoverflow.com/questions/55923290/consistent-math-equation-numbering-in-bookdown-across-pdf-docx-html-output --> -->

<!-- \begin{equation} -->
<!-- \label{eqn:johansens} -->
<!-- \Delta y_t = \Pi y_{t-1} + \sum_{j = 1}^{p-1} {\Gamma_j \Delta y_{t-j}} + \varepsilon_t -->
<!-- \end{equation} -->

<!-- Where, -->

<!-- $$ -->
<!-- \Pi = \sum^{p}_{i = 1}{A_{i}-I}; \Gamma = -\sum^{p}_{j = i + 1}{j} -->
<!-- $$ -->

<!-- (Although, for simplicity sake, we assume absence of deterministic trends, there are five popular scenarios of including such trends in a cointegration test. All of these are described in [@johansen1995identifying].) -->

<!-- Granger's representation theorem asserts that if the coefficient matrix $\Pi$ has reduced rank $r < k$, then there exist $kxr$ matrices $\alpha$ and $\beta$ each with rank $k$ such that $\Pi = \alpha \beta^{\prime}$ and $\beta^{\prime}y_t$ is $I(0)$. -->

<!-- To achieve this an eigenvalue decomposition of $A$ is carried out. The rank of the matrix $A$ is given by $r$ and the Johansen test sequentially tests whether this rank $r$ is equal to zero, equal to one, through to $r=n-1$, where $n$ is the number of time series under test. -->

<!-- The null hypothesis of $r=0$ means that there is no cointegration at all. A rank $r > 0$ implies a cointegrating relationship between two or possibly more time series. -->

<!-- The eigenvalue decomposition results in a set of eigenvectors. The components of the largest eigenvector admits the important property of forming the coefficients of a linear combination of time series to produce a stationary portfolio. Notice how this differs from the CADF test (often known as the Engle-Granger procedure) where it is necessary to ascertain the linear combination a priori via linear regression and ordinary least squares (OLS). -->

<!-- In summary, the test checks for the situation of no cointegration, which occurs when the matrix $A=0$. So, starting with the base value of $r$ (i.e., $r=0$), if the test statistic is greater than critical values of at the 10%, 5% and 1% levels, this would imply that we are **able** to reject the null of no cointegration. For the case r<=1, we if the calculated test statistic is below the critical values of, we are **unable** to reject the null, and the number of cointegrating vectors is between 0 and 1. The relevant tests are available in the function `urca::ca.jo()`. The basic version considers the eigenvalues of the matrix $\Pi$ in the preceding equation. -->

<!-- Here, we employ the trace statistic -- the maximum eigenvalue, or "lambdamax" test is available as well -- in an equation amended by a constant term (specified by ecdet = "const"), yielding: -->

<!-- ```{r cajo-test-procedure} -->

<!-- # # Johansens cointegration test -->
<!-- # # data -->
<!-- # retail_mhub_cmwise # (generated in code chunk 'series-mktname-wise-cname') -->
<!-- # pairwise_series_name # (generated in code chunk 'pairwise-phillips-cointegration') -->

<!-- # rice_series_combination # (generated in code chunk 'series-mktname-wise-cname') -->
<!-- # wheat_series_combination # (generated in code chunk 'series-mktname-wise-cname') -->

<!-- # # ca.jo test -->
<!-- rice_series_combination_cajo_test <- map(rice_series_combination, ~urca::ca.jo(log(.x), ecdet = "const", type = "trace")) %>%  -->
<!--   set_names(unite(as_tibble(pairwise_series_name), col = "single_col", sep = "-")$`single_col`) -->

<!-- wheat_series_combination_cajo_test <- map(wheat_series_combination, ~urca::ca.jo(log(.x), ecdet = "const", type = "trace")) %>%  -->
<!--   set_names(unite(as_tibble(pairwise_series_name), col = "single_col", sep = "-")$`single_col`) -->

<!-- ``` -->

<!-- Johansen cointegration test summary and time series plots for rice (district marketwise) -->

<!-- ```{r rice-cajo-test, fig.width=6, out.width="90%", results='asis'} -->
<!-- rice_series_combination_cajo_test_tidy <- map(rice_series_combination_cajo_test, ~summary(.x)) %>%  -->
<!--   # .[1] %>%  -->
<!--   map(.f = function(x){ -->
<!--     map(.x = c("model", "type", "teststat", "cval", "lambda", "V", "W"), .f = function(y)slot(x, y)) -->
<!--     }) -->


<!-- # test statistic and confidence interval summary of log(price) -->
<!-- rice_series_combination_cajo_test_statcval <- map(rice_series_combination_cajo_test_tidy, ~cbind(test_stat = .x[[3]], conf_val = .x[[4]]) %>%  -->
<!--                                                      as_tibble(rownames = "gamma")) %>%  -->
<!--   map2(.y = names(.),  -->
<!--        .f = ~.x %>%  -->
<!--          knitr::kable(caption = paste("Johansen cointegration test summary for", .y), booktabs = TRUE, longtable = TRUE)) -->
<!-- walk(rice_series_combination_cajo_test_statcval, print) -->

<!-- # map(rice_series_combination_cajo_test, ~plot(.x)) -->
<!-- ``` -->


<!-- Johansen cointegration test summary and time series plots for wheat (district marketwise) -->

<!-- ```{r wheat-cajo-test, fig.width=6, out.width="90%", results='asis'} -->
<!-- wheat_series_combination_cajo_test_tidy <- map(wheat_series_combination_cajo_test, ~summary(.x)) %>%  -->
<!--   # .[1] %>%  -->
<!--   map(.f = function(x){ -->
<!--     map(.x = c("model", "type", "teststat", "cval", "lambda", "V", "W"), .f = function(y)slot(x, y)) -->
<!--     }) -->

<!-- # test statistic and confidence interval summary of log(price) -->
<!-- wheat_series_combination_cajo_test_statcval <- map(wheat_series_combination_cajo_test_tidy, ~cbind(test_stat = .x[[3]], conf_val = .x[[4]]) %>%  -->
<!--                                                      as_tibble(rownames = "gamma")) %>%  -->
<!--   map2(.y = names(.),  -->
<!--        .f = ~.x %>%  -->
<!--          knitr::kable(caption = paste("Johansen cointegration test summary for", .y), booktabs = TRUE, longtable = TRUE)) -->
<!-- walk(wheat_series_combination_cajo_test_statcval, print) -->

<!-- # map(wheat_series_combination_cajo_test, ~plot(.x, type = "single")) -->
<!-- ``` -->


<!-- ```{r wheat-rice-ci-out-bind} -->

<!-- wheat_series_combination_cajo_test_ci_out <- map(wheat_series_combination_cajo_test,  -->
<!--     ~.x@x %*% .x@V[-(.x@P + 1), ]) -->
<!-- rice_series_combination_cajo_test_ci_out <- map(rice_series_combination_cajo_test,  -->
<!--     ~.x@x %*% .x@V[-(.x@P + 1), ]) -->

<!-- ``` -->


<!-- ```{r grid-arrange-share-legend} -->
<!-- grid_arrange_share_legend_m <- function(..., nrow = 1, ncol = length(list(...)), position = c("bottom", "right")) { -->
<!--   plots <- list(...) -->
<!--   position <- match.arg(position) -->
<!--   g <- ggplot2::ggplotGrob(plots[[1]] + ggplot2::theme(legend.position = position))$grobs -->
<!--   legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]] -->
<!--   lheight <- sum(legend$height) -->
<!--   lwidth <- sum(legend$width) -->
<!--   gl <- lapply(plots, function(x) x + theme(legend.position = "none")) -->
<!--   gl <- c(gl, nrow = nrow, ncol = ncol) -->

<!--   combined <- switch(position, -->
<!--                      "bottom" = gridExtra::arrangeGrob(do.call(gridExtra::arrangeGrob, gl), -->
<!--                                                        legend, -->
<!--                                                        ncol = 1, -->
<!--                                                        heights = grid::unit.c(unit(1, "npc") - lheight, lheight)), -->
<!--                      "right" = gridExtra::arrangeGrob(do.call(gridExtra::arrangeGrob, gl), -->
<!--                                                       legend, -->
<!--                                                       ncol = 2, -->
<!--                                                       widths = grid::unit.c(unit(1, "npc") - lwidth, lwidth))) -->
<!--   return(combined) -->
<!-- } -->
<!-- ``` -->

<!-- Wheat series and cointegration plots -->

<!-- ```{r wheat-coint-plots, fig.width=10, fig.height=6, out.width="100%", fig.show='hold', fig.align='center'} -->
<!-- # first variable series -->
<!-- wheat_series_ci_df1 <- map2(wheat_series_combination_cajo_test,  -->
<!--                             wheat_series_combination_cajo_test_ci_out, -->
<!--                             ~.x@x[, 1] %>%  -->
<!--                               as_tsibble() %>%  -->
<!--                               mutate(ci_test = .y[, 1])) -->

<!-- wheat_series_ci_df1_bind <- wheat_series_ci_df1 %>%  -->
<!--   map_dfr(c, .id = "which_pair") %>%  -->
<!--   as_tsibble(index = "index", key = which_pair) -->

<!-- wheat_series_df1_bind_var_gg <- wheat_series_ci_df1_bind %>% -->
<!--   ggplot(aes(x = index, y = value, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   ggtitle("Pairs of time series plot of y1 variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- wheat_series_ci_df1_bind_var_gg <- wheat_series_ci_df1_bind %>%  -->
<!--   ggplot(aes(x = index, y = ci_test, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   ggtitle("Pairs of cointegration relation of 1st variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- # second variable series -->
<!-- wheat_series_ci_df2 <- map2(wheat_series_combination_cajo_test,  -->
<!--                             wheat_series_combination_cajo_test_ci_out, -->
<!--                             ~.x@x[, 2] %>%  -->
<!--                               as_tsibble() %>%  -->
<!--                               mutate(ci_test = .y[, 2])) -->

<!-- wheat_series_ci_df2_bind <- wheat_series_ci_df2 %>%  -->
<!--   map_dfr(c, .id = "which_pair") %>%  -->
<!--   as_tsibble(index = "index", key = which_pair) -->

<!-- wheat_series_df2_bind_var_gg <- wheat_series_ci_df2_bind %>% -->
<!--   ggplot(aes(x = index, y = value, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   ggtitle("Pairs of time series plot of y2 variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- wheat_series_ci_df2_bind_var_gg <- wheat_series_ci_df2_bind %>%  -->
<!--   ggplot(aes(x = index, y = ci_test, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   # scale_color_discrete(name = "Market region") + -->
<!--   ggtitle("Pairs of cointegration relation of 2nd variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- wheat_lprice_series_gg <- grid_arrange_share_legend_m(wheat_series_df1_bind_var_gg, wheat_series_df2_bind_var_gg, ncol = 2, position = "bottom") -->
<!-- wheat_ci_series_gg <- grid_arrange_share_legend_m(wheat_series_ci_df1_bind_var_gg, wheat_series_ci_df2_bind_var_gg, ncol = 2, position = "bottom") -->

<!-- plot(wheat_lprice_series_gg) -->
<!-- plot(wheat_ci_series_gg) -->

<!-- # walk2(c("./output/wheat_lprice_series_gg.png", "./output/wheat_ci_series_gg.png"), -->
<!-- #      list(wheat_lprice_series_gg, wheat_ci_series_gg), -->
<!-- #      ~ggsave(.x, .y, device = "png", width = 12, height = 8, units = "in", dpi = 280)) -->

<!-- ``` -->

<!-- Rice series and cointegration plots -->

<!-- ```{r rice-coint-plots, fig.width=10, fig.height=6, out.width="100%", fig.show='hold', fig.align='center'} -->
<!-- # first variable series -->
<!-- rice_series_ci_df1 <- map2(rice_series_combination_cajo_test,  -->
<!--                             rice_series_combination_cajo_test_ci_out, -->
<!--                             ~.x@x[, 1] %>%  -->
<!--                               as_tsibble() %>%  -->
<!--                               mutate(ci_test = .y[, 1])) -->

<!-- rice_series_ci_df1_bind <- rice_series_ci_df1 %>%  -->
<!--   map_dfr(c, .id = "which_pair") %>%  -->
<!--   as_tsibble(index = "index", key = which_pair) -->

<!-- rice_series_df1_bind_var_gg <- rice_series_ci_df1_bind %>% -->
<!--   ggplot(aes(x = index, y = value, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   ggtitle("Pairs of time series plot of y1 variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- rice_series_ci_df1_bind_var_gg <- rice_series_ci_df1_bind %>%  -->
<!--   ggplot(aes(x = index, y = ci_test, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   ggtitle("Pairs of cointegration relation of 1st variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- # second variable series -->
<!-- rice_series_ci_df2 <- map2(rice_series_combination_cajo_test,  -->
<!--                             rice_series_combination_cajo_test_ci_out, -->
<!--                             ~.x@x[, 2] %>%  -->
<!--                               as_tsibble() %>%  -->
<!--                               mutate(ci_test = .y[, 2])) -->

<!-- rice_series_ci_df2_bind <- rice_series_ci_df2 %>%  -->
<!--   map_dfr(c, .id = "which_pair") %>%  -->
<!--   as_tsibble(index = "index", key = which_pair) -->

<!-- rice_series_df2_bind_var_gg <- rice_series_ci_df2_bind %>% -->
<!--   ggplot(aes(x = index, y = value, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   ggtitle("Pairs of time series plot of y2 variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- rice_series_ci_df2_bind_var_gg <- rice_series_ci_df2_bind %>%  -->
<!--   ggplot(aes(x = index, y = ci_test, color = which_pair)) + -->
<!--   geom_line() + -->
<!--   # scale_color_discrete(name = "Market region") + -->
<!--   ggtitle("Pairs of cointegration relation of 2nd variable") + -->
<!--   guides(color = guide_legend(title = "Market region")) + -->
<!--   labs(x = "Date", y = NULL) -->

<!-- rice_lprice_series_gg <- grid_arrange_share_legend_m(rice_series_df1_bind_var_gg, rice_series_df2_bind_var_gg, ncol = 2, position = "bottom") -->
<!-- rice_ci_series_gg <- grid_arrange_share_legend_m(rice_series_ci_df1_bind_var_gg, rice_series_ci_df2_bind_var_gg, ncol = 2, position = "bottom") -->

<!-- plot(rice_lprice_series_gg) -->
<!-- plot(rice_ci_series_gg) -->

<!-- # walk2(c("./output/rice_lprice_series_gg.png", "./output/rice_ci_series_gg.png"), -->
<!-- #      list(rice_lprice_series_gg, rice_ci_series_gg), -->
<!-- #      ~ggsave(.x, .y, device = "png", width = 12, height = 8, units = "in", dpi = 280)) -->

<!-- ``` -->


# Bibliography
